{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RichardWang11/DGCN/blob/master/markov_basic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWMQMCMEsuEB"
      },
      "outputs": [],
      "source": [
        "!pip install markovify"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TNvCF3EnvaPj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "450665f2-83be-47ee-f4a4-069618561aed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/markov_copus\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/markov_copus')\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load dataset from english book**"
      ],
      "metadata": {
        "id": "FBJE1RgqYN_Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LSoChCJ9TiLX"
      },
      "outputs": [],
      "source": [
        "!wget https://www.gutenberg.org/cache/epub/74979/pg74979.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training on IMDB**"
      ],
      "metadata": {
        "id": "oDcDaS-SYW29"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNr84o5qvh2D"
      },
      "outputs": [],
      "source": [
        "### test On IMDB########\n",
        "import os\n",
        "import markovify\n",
        "\n",
        "# Base path to your dataset\n",
        "base_path = \"/content/drive/MyDrive/markov_copus/dataset/aclImdb/train\"\n",
        "directories = [\"pos\", \"neg\", \"unsup\"]\n",
        "\n",
        "# Initialize the combined Markov model as None\n",
        "combined_model = None\n",
        "\n",
        "# Function to read files safely\n",
        "def safe_read_file(file_path):\n",
        "    try:\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            text = f.read().strip()\n",
        "            if not text:  # Skip empty files\n",
        "                print(f\"Skipped empty file: {file_path}\")\n",
        "                return None\n",
        "            return text\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading file {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Loop through the directories and process each file\n",
        "for directory in directories:\n",
        "    dir_path = os.path.join(base_path, directory)\n",
        "    for file_name in os.listdir(dir_path):\n",
        "        if file_name.endswith(\".txt\"):\n",
        "            file_path = os.path.join(dir_path, file_name)\n",
        "            text = safe_read_file(file_path)\n",
        "            if text:\n",
        "                try:\n",
        "                    # Use NewlineText for better sentence handling\n",
        "                    model = markovify.NewlineText(text, retain_original=False)\n",
        "                    # Combine the models\n",
        "                    if combined_model:\n",
        "                        combined_model = markovify.combine(models=[combined_model, model])\n",
        "                    else:\n",
        "                        combined_model = model\n",
        "                except KeyError as e:\n",
        "                    # Handle files causing `('___BEGIN__', '___BEGIN__')` errors\n",
        "                    print(f\"Skipped problematic file {file_path}: {e}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Unexpected error processing file {file_path}: {e}\")\n",
        "\n",
        "# Generate sentences from the combined model\n",
        "if combined_model:\n",
        "    print(\"\\nGenerated Sentences:\")\n",
        "    for i in range(5):\n",
        "        sentence = combined_model.make_sentence(tries=100)\n",
        "        if sentence:\n",
        "            print(sentence)\n",
        "        else:\n",
        "            print(\"Failed to generate a valid sentence. Try increasing 'tries'.\")\n",
        "else:\n",
        "    print(\"No valid text files found or failed to generate the model.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCbCDoHvd59Z",
        "outputId": "e8765d73-a628-4b1a-f528-3a2f56a14323"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A beautiful shopgirl in London is swept off her feet by a millionaire tea plantation owner and soon finds herself married and living with him at his villa in British Ceylon. Although based upon the book by Robert Standish, this initial set-up is highly reminiscent of Hitchock's \"Rebecca\", with leading lady Elizabeth Taylor clashing with the imposing chief of staff at the mansion and (almost immediately) her own husband, who is still under the thumb of his deceased-but-dominant father. Taylor, a last-minute substitute for an ailing Vivien Leigh, looks creamy-smooth in her high fashion wardrobe, and her performance is quite strong; however, once husband Peter Finch starts drinking heavily and barking orders at her, one might think her dedication to him rather masochistic (this feeling hampers the ending as well). Still, the film offers a heady lot for soap buffs: romantic drama, a bit of travelogue, interpretive dance, an elephant stampede, and a perfectly-timed outbreak of cholera! *** from ****\n"
          ]
        }
      ],
      "source": [
        "with open(\"/content/drive/MyDrive/markov_copus/dataset/aclImdb/train/pos/10093_7.txt\") as f:\n",
        "  text = f.read()\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_y1S69xSenCK",
        "outputId": "dec3b8f0-190a-4ec7-9e4c-97060b870ad3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['quickly', 'the', 'dog', 'walks', 'slowly']\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import random\n",
        "import json\n",
        "from bisect import bisect\n",
        "from collections import defaultdict\n",
        "from typing import List, Dict, Union, Tuple\n",
        "\n",
        "\n",
        "BEGIN = \"___BEGIN__\"\n",
        "END = \"___END__\"\n",
        "\n",
        "\n",
        "class MarkovChain:\n",
        "    \"\"\"\n",
        "    A class for creating and using a Markov Chain model.\n",
        "    \"\"\"\n",
        "    def __init__(self, order: int, data: List[List[str]]):\n",
        "        self.order = order\n",
        "        self.data = data\n",
        "        self.model = defaultdict(lambda: defaultdict(int))\n",
        "        self._build_model()\n",
        "\n",
        "    def _build_model(self, ):\n",
        "        \"\"\"Builds the Markov Chain model from the given data.\"\"\"\n",
        "        for sentence in self.data: # 假设句子之间用空格分隔\n",
        "            words = ([BEGIN] * self.order) + sentence + [END]\n",
        "            for i in range(len(words) - self.order):\n",
        "                state = tuple(words[i:i+self.order])\n",
        "                next_state = words[i+self.order]\n",
        "                self.model[state][next_state] += 1\n",
        "\n",
        "        for state in self.model:\n",
        "            total = sum(self.model[state].values())\n",
        "            for next_state in self.model[state]:\n",
        "                self.model[state][next_state] /= total\n",
        "\n",
        "    def generate(self, length: int, start: Union[str, None] = None) -> List[str]:\n",
        "        \"\"\"Generates a sequence of states of the given length.\"\"\"\n",
        "        if start is None:\n",
        "            start = random.choice(list(self.model.keys()))\n",
        "        else:\n",
        "            start = tuple(start[-self.order:])\n",
        "\n",
        "        result = list(start)\n",
        "        for _ in range(length - self.order):\n",
        "            next_state = self._sample_next_state(start)\n",
        "            result.append(next_state)\n",
        "            start = tuple(result[-self.order:])\n",
        "\n",
        "        return result\n",
        "\n",
        "    def _sample_next_state(self, state: Tuple[str]) -> str:\n",
        "        \"\"\"Samples the next state based on the probabilities in the model.\"\"\"\n",
        "        probabilities = list(self.model[state].values())\n",
        "        states = list(self.model[state].keys())\n",
        "        return random.choices(states, probabilities)[0]\n",
        "\n",
        "    def save_model(self, file_path: str):\n",
        "        with open(file_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(self.model, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "    @classmethod\n",
        "    def load_model(self, file_path: str):\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            self.model = json.load(f)\n",
        "\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # 示例数据，这里简单模拟了一些单词组成的序列，实际应用中可以从文件读取文本并进行分词等处理来获取更丰富的数据\n",
        "    data = [[\"the\", \"cat\", \"runs\", \"quickly\", \"the\", \"dog\", \"walks\", \"slowly\", \"the\", \"bird\", \"flies\", \"high\"]]\n",
        "    # 创建马尔可夫链模型实例，设置阶数为2\n",
        "    markov_chain = MarkovChain(2, data)\n",
        "\n",
        "    # 使用模型生成一个长度为10的新序列，不指定起始状态（将随机选择起始状态）\n",
        "    generated_sequence = markov_chain.generate(5)\n",
        "    print(generated_sequence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUD2wIYQ-OEE",
        "outputId": "a7d881f3-f1e4-4ddf-ce5f-c96ddeb10890"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BLEU Scores for each sentence:\n",
            "Sentence 1: 0.0395\n",
            "Sentence 2: 0.1267\n",
            "Sentence 3: 0.1514\n",
            "Sentence 4: 0.0170\n",
            "Sentence 5: 0.1740\n",
            "\n",
            "Average BLEU Score: 0.1017\n"
          ]
        }
      ],
      "source": [
        "## 评价生成的句子 评价指标bleu\n",
        "from evaluation import evaluate_bleu\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 示例参考句子（可以替换为你的参考句子）\n",
        "    reference_sentences = [\n",
        "        \"Those waterless wells must have been dry for years.\",\n",
        "        \"I thought of the ghost on the green hill stirring in the wind.\",\n",
        "        \"I could find no sign of life anywhere in the ruins.\",\n",
        "        \"The ebook is now available for free, and can be downloaded easily.\",\n",
        "        \"There is very little light in this room, and it is hard to see.\"\n",
        "    ]\n",
        "\n",
        "    # 示例生成句子（可以替换为生成的句子）\n",
        "    generated_sentences = [\n",
        "        \"Those waterless wells, must have read, I seemed tricks in the strength of his mind.\",\n",
        "        \"I thought of the ghost for the green of the stir of it takes a click and had nothing on the subsiding red joint I stooped to light of agriculture; the mantel and open hill.\",\n",
        "        \"I could find no wasting my mind came blundering into a Morlock or dried grass of yore.\",\n",
        "        \"This ebook is now, and, as a steady twilight brooded over to provide a foolish moment, and startling some carnal cravings, I would amaze our position.\",\n",
        "        \"There is very little people came a peculiar manner, to the tension by their eyes.\"\n",
        "    ]\n",
        "\n",
        "    # 调用 evaluate_bleu 函数计算 BLEU 分数\n",
        "    bleu_scores, average_bleu = evaluate_bleu(reference_sentences, generated_sentences)\n",
        "\n",
        "    # 输出每个句子的 BLEU 分数\n",
        "    print(\"BLEU Scores for each sentence:\")\n",
        "    for i, score in enumerate(bleu_scores):\n",
        "        print(f\"Sentence {i + 1}: {score:.4f}\")\n",
        "\n",
        "    # 输出平均 BLEU 分数\n",
        "    print(f\"\\nAverage BLEU Score: {average_bleu:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install rouge"
      ],
      "metadata": {
        "id": "rDN2HCsjY3aY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing**\n",
        "\n",
        "\n",
        "*   *Observations:*\n",
        "1. Unnecessary Markers:\n",
        "\n",
        "Section markers like = Missouri River =, = Major tributaries =, or = = = ... = = = should be removed.\n",
        "2. Extra Spaces:\n",
        "\n",
        "There are redundant spaces around punctuation and between words, which need to be normalized.\n",
        "3. Structured Information:\n",
        "\n",
        "Some content is in a structured, encyclopedic format (e.g., lists or detailed descriptions). Depending on your task, you might want to remove sections with excessive detail (like lists or tables) or retain only the narrative content.\n",
        "4. Punctuation Artifacts:\n",
        "\n",
        "The text is generally clean of tokenization artifacts, but formatting (like numbers and units) could be normalized for consistency.\n",
        "*   *Goals*\n",
        "1. Remove unnecessary section markers.\n",
        "2. Normalize spaces and punctuation.\n",
        "3. Keep the text in a natural narrative form.\n",
        "\n"
      ],
      "metadata": {
        "id": "2n7ylCVRa7yy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_wikitext(text):\n",
        "    \"\"\"\n",
        "    Cleans Wikitext data for modeling or evaluation.\n",
        "    - Removes section headers (e.g., \"= Section =\").\n",
        "    - Normalizes spaces and line breaks.\n",
        "    - Optionally removes non-narrative content like tables or lists.\n",
        "    Args:\n",
        "        text (str): The raw input text.\n",
        "    Returns:\n",
        "        str: The cleaned text.\n",
        "    \"\"\"\n",
        "    # Remove section headers (e.g., \"= Section =\")\n",
        "    text = re.sub(r'=+\\s*.*?\\s*=+', '', text)\n",
        "\n",
        "    # Replace multiple spaces/newlines with a single space\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    # (Optional) Normalize punctuation (remove extra spaces around punctuation)\n",
        "    text = re.sub(r'\\s([?.!,;:\\'\\\"])', r'\\1', text)  # Remove space before punctuation\n",
        "    text = re.sub(r'([?.!,;:\\'\\\"])\\s', r'\\1 ', text)  # Ensure space after punctuation\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Final space normalization\n",
        "\n",
        "    return text\n",
        "\n",
        "\n",
        "# # Apply the cleaning function to a sample text\n",
        "# raw_text = \"\"\"\n",
        "# = = = Air support and logistics = = =\n",
        "\n",
        "# Aerial operations for the incursion got off to a slow start . Reconnaissance flights over the operational area were restricted since MACV believed that they might serve as a signal of intention . The role of the Air Force in the planning for the incursion itself was minimal at best , in part to preserve the secrecy of Menu which was then considered an overture to the thrust across the border .\n",
        "# \"\"\"\n",
        "\n",
        "# cleaned_text = clean_wikitext(raw_text)\n",
        "# print(cleaned_text)\n"
      ],
      "metadata": {
        "id": "35VbHZuNa_Kz"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Dataset from wikiText**"
      ],
      "metadata": {
        "id": "KzVff5V7Yl00"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load the Wikitext-2-raw-v1 dataset\n",
        "dataset = load_dataset(\"Salesforce/wikitext\", \"wikitext-2-raw-v1\")\n",
        "\n",
        "cleaned_train_data = [clean_wikitext(example['text']) for example in dataset['train']]\n",
        "cleaned_val_data = [clean_wikitext(example['text']) for example in dataset['validation']]\n",
        "cleaned_test_data = [clean_wikitext(example['text']) for example in dataset['test']]\n",
        "# Save the cleaned splits to text files\n",
        "with open(\"cleaned_train.txt\", \"w\") as f:\n",
        "    for line in cleaned_train_data:\n",
        "        f.write(line + \"\\n\")\n",
        "with open(\"cleaned_validation.txt\", \"w\") as f:\n",
        "    for line in cleaned_val_data:\n",
        "        f.write(line + \"\\n\")\n",
        "\n",
        "with open(\"cleaned_test.txt\", \"w\") as f:\n",
        "    for line in cleaned_test_data:\n",
        "        f.write(line + \"\\n\")\n",
        "# Print examples from each cleaned split\n",
        "print(\"Cleaned Train Example:\", cleaned_train_data[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MU8XUP_AYlI6",
        "outputId": "50b374c5-f040-4fc9-9507-1014a37514af"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned Train Example: Senjō no Valkyria 3: Unrecorded Chronicles ( Japanese: 戦場のヴァルキュリア3, lit. Valkyria of the Battlefield 3 ), commonly referred to as Valkyria Chronicles III outside Japan, is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable. Released in January 2011 in Japan, it is the third game in the Valkyria series. Employing the same fusion of tactical and real @-@ time gameplay as its predecessors, the story runs parallel to the first game and follows the\" Nameless\", a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit\" Calamaty Raven\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over the training data\n",
        "for example in cleaned_train_data:\n",
        "    print(example)  # Each example contains a 'text' field"
      ],
      "metadata": {
        "id": "p8hBMEy0Z98e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import markovify\n",
        "\n",
        "# Load the cleaned text with sentences on new lines\n",
        "with open(\"/content/drive/MyDrive/markov_copus/dataset/wikiText/cleaned_train.txt\", \"r\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "# Build the Markovify model using NewlineText\n",
        "text_model = markovify.NewlineText(text)\n",
        "\n",
        "# Print generated sentences\n",
        "print(\"Randomly generated sentences:\")\n",
        "for i in range(5):\n",
        "    print(text_model.make_sentence())\n",
        "# # Print three randomly-generated sentences of no more than 280 characters\n",
        "print(\"\\nRandomly generated short sentences:\")\n",
        "for i in range(3):\n",
        "    print(text_model.make_short_sentence(280))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wK9mVZiidFDz",
        "outputId": "2a7a8cc6-c178-4f77-f0b1-f7e2fc9ce2ba"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Randomly generated sentences:\n",
            "East Carolina had been phased out since 1969.\n",
            "In 1999, at the Groesbeek Memorial. Major Robert Henry Cain, also of 2nd Battalion, 27th Infantry Regiment, in at the elite level, although they take him back. Daisuke Aramaki, head of the estuary of national debt, prejudicial trade policies by other sequences. For instance, Khnum was the third disc. It also made minor appearances.\n",
            "syān @-@ nāsti @-@ avaktavyaḥ — in the top flight performers, but City were relegated with Notts County manager, Lawton ran the Ministries of Labor and Health, founded and ran the ball shoots one free throw line and then deal with the development of a large parsonage in Mechtshausen. Busch read biographies, novels and stories of fox possession still occur, such as UV Ceti may also have a polygynous lek breeding system. It is sedentary over its lifetime, all designed by Timothy L. Pflueger in the teachings of Mahāvīra, who used it for its return. For example, he would do in Congress on their robes at all of these pressures, the IUCN Red List species as of 1 @,@ 250 were buried within a vacuum cleaner pipe serves as the fly agaric or fly amanita, is a cross @-@ examine witnesses, and to produce peptides in high school and rugby union team represents the story's serious tone. Points criticized in the UK and PBS in the Shell remake is scheduled to be a day @-@ to @-@ day disabled list upon signing to continue coaching youth baseball camps and units were transferred to Townsville for the first water @-@ borne stomach diseases.\n",
            "The soldiers keenly listen to the playoffs in 1943 as Maidan Castle, Dorset. The report's publication allowed further criticism to be in search of Shiva to atone for their June 3 @-@ test series against Germany. She was credited with hits on several occasions in prose. Stanley Woolley, a character in the League Cup tie against Reading, scoring just two qualifying games for the J @-@ pop phenomenon.\n",
            "A map of all cancer deaths in New York. When the NY 312 designation was shifted south to the grievance or dishonour of the water; by 02: 20, the screws and both ambulances arrived in Alexandria, Egypt on 11 December. On 30 April, and another from Nîmes.\n",
            "\n",
            "Randomly generated short sentences:\n",
            "Throughout the rest of the cabinet, the white monopoly on offshore flights. However, the British ship, inflicting significant damage to the 1980s.\n",
            "A Confession of Faith to replace him, and his companions moved throughout the NBA and appeared on the British paratroopers. At the start vertex of the bypass tunnels, as the case is solved.\n",
            "At 05: 30 on 7 October 1987. She carried the ship's cargo was loaded in Greenock in early 1229 to conclude negotiations with envoys of the athletes. If the athlete should not be recognized immediately, because the parasite infects and sterilizes the eggs of the magazine.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation with BLEU score**:\n",
        "The BLEU (Bilingual Evaluation Understudy) score measures how closely the generated sentences match reference sentences."
      ],
      "metadata": {
        "id": "fuwt-jzflh3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "import markovify\n",
        "\n",
        "# Load the cleaned reference text (validation or test data)\n",
        "with open(\"/content/drive/MyDrive/markov_copus/dataset/wikiText/cleaned_test.txt\", \"r\") as f:\n",
        "    reference_sentences = f.readlines()\n",
        "\n",
        "# Load the Markov model\n",
        "with open(\"/content/drive/MyDrive/markov_copus/dataset/wikiText/cleaned_train.txt\", \"r\") as f:\n",
        "    text = f.read()\n",
        "text_model = markovify.NewlineText(text)\n",
        "\n",
        "# Generate sentences using the Markov model\n",
        "generated_sentences = [text_model.make_sentence() for _ in range(10)]\n",
        "\n",
        "# Evaluate BLEU score\n",
        "smoothing_function = SmoothingFunction().method1  # To handle edge cases\n",
        "bleu_scores = []\n",
        "\n",
        "for gen_sentence in generated_sentences:\n",
        "    if gen_sentence:  # Ignore None outputs\n",
        "        # Use all reference sentences to calculate BLEU score for each generated sentence\n",
        "        references = [ref.split() for ref in reference_sentences]\n",
        "        gen_tokens = gen_sentence.split()\n",
        "        score = sentence_bleu(references, gen_tokens, smoothing_function=smoothing_function)\n",
        "        bleu_scores.append(score)\n",
        "\n",
        "# Print the BLEU scores for each generated sentence\n",
        "print(\"Generated Sentences and BLEU Scores:\")\n",
        "for i, (gen_sentence, score) in enumerate(zip(generated_sentences, bleu_scores)):\n",
        "    print(f\"Sentence {i + 1}: {gen_sentence}\")\n",
        "    print(f\"BLEU Score: {score:.4f}\")\n",
        "\n",
        "# Calculate the average BLEU score\n",
        "avg_bleu = sum(bleu_scores) / len(bleu_scores) if bleu_scores else 0\n",
        "print(f\"\\nAverage BLEU Score: {avg_bleu:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_qg6y61fJK5",
        "outputId": "e2882d3d-1292-4e27-93ef-235d8ab7aa73"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Sentences and BLEU Scores:\n",
            "Sentence 1: Many federal groups at 100 McAllister served as headquarters of the most problematic and worst @-@ sounding to the formation of the record. Federer turned the tide at the gravesite of Edward II led to her by impaling her through the proportional representation with the management's artistic freedom, but Olivier himself stayed firmly in place, but little was done with three grade As. From there Pryce went on to win the game.\n",
            "BLEU Score: 0.1629\n",
            "Sentence 2: Some original costumes were designed by H. R. Giger, also responsible for porting the Guitar Hero games is a side @-@ scrolling platform video game, the player shooting the free kick, Alabama scored on a one @-@ hour duel, sailing at 11: 20 they were unique Astraeus species, including sub @-@ districts have pending AOC applications to become the subject matter or the Sun.\n",
            "BLEU Score: 0.0784\n",
            "Sentence 3: In June 1877, at the route's northern terminus. This construction consisted of former Looking Glass employees.\n",
            "BLEU Score: 0.0596\n",
            "Sentence 4: More generally, ancient Egyptians seem to have been identified, including: other blood disorders, chemical exposures, ionizing radiation, and genetics.\n",
            "BLEU Score: 0.0938\n",
            "Sentence 5: The French Atlantic Fleet.\n",
            "BLEU Score: 0.2021\n",
            "Sentence 6: Regarded throughout his career and became their inaugural marquee player; with his parents to children which include:\n",
            "BLEU Score: 0.2329\n",
            "Sentence 7: Attempt to found what is now one of the games. In November 2006, joining Rushden & Diamonds. He then reached NC State by two massive stone structures, which resemble titla. Because writing materials such as faeces or dead nestlings. Protozoan blood parasites of the blood of smokers is 4 times greater nitrosamine exposure from food and providing for the charity Acorns Children's Hospice, the first @-@ down type output terminals; later models had screw terminals.\n",
            "BLEU Score: 0.0585\n",
            "Sentence 8: By this time he was elected as a hunting trip in the bandit cart and kill frozen zombies before they captured Tianzuo, the last season of excavation and recording. Further, he is shocked to see such former footballers as George Best and Kevin Keegan. In 2015, Stansfield was diagnosed with a scene which is around 7 per cent budget increase for the chapters. He eventually abandoned and the All @-@ ACC receiver Nasrallah Worthen, who led the Hokies during their shows. These link @-@ ups late in 1908, with Benson's encouragement. A correspondence ensued and in the field. After a bad snap. After the fall in 36 games in the burial record of Thomas Pynchon's 2009 novel Inherent Vice\n",
            "BLEU Score: 0.1653\n",
            "Sentence 9: In the Fastra II's predecessor, the Fastra II was later adapted into a remnant low.\n",
            "BLEU Score: 0.1138\n",
            "Sentence 10: Aside from humans, no species preys upon mature cougars in the early days of the village of Bình Giã from the southwest. At the same reachability relation described by David Conway\n",
            "BLEU Score: 0.2992\n",
            "\n",
            "Average BLEU Score: 0.1466\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation with ROUGE Scores:**\n",
        "\n",
        "ROUGE-1: Measures overlap of unigrams (single words).\n",
        "ROUGE-2: Measures overlap of bigrams (two-word sequences).\n",
        "ROUGE-L: Measures the longest common subsequence (LCS) between the generated and reference texts."
      ],
      "metadata": {
        "id": "eC3Y_f3Wm89R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge import Rouge\n",
        "import markovify\n",
        "\n",
        "# Load the reference sentences from the validation or test file\n",
        "with open(\"/content/drive/MyDrive/markov_copus/dataset/wikiText/cleaned_test.txt\", \"r\") as f:\n",
        "    reference_sentences = f.readlines()\n",
        "\n",
        "# Load the cleaned training text for Markovify\n",
        "with open(\"/content/drive/MyDrive/markov_copus/dataset/wikiText/cleaned_train.txt\", \"r\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "# Build the Markovify model\n",
        "text_model = markovify.NewlineText(text)\n",
        "\n",
        "# Generate sentences using the Markov model\n",
        "generated_sentences = [text_model.make_sentence() for _ in range(5)]\n",
        "\n",
        "# Initialize the ROUGE scorer\n",
        "rouge = Rouge()\n",
        "\n",
        "# Evaluate ROUGE scores for each generated sentence\n",
        "print(\"Generated Sentences and ROUGE Scores:\")\n",
        "for i, gen_sentence in enumerate(generated_sentences):\n",
        "    if gen_sentence:  # Ignore None outputs\n",
        "        # Compute ROUGE scores for the generated sentence against all references\n",
        "        scores = rouge.get_scores(gen_sentence, \" \".join(reference_sentences), avg=True)\n",
        "        print(f\"Sentence {i + 1}: {gen_sentence}\")\n",
        "        print(f\"ROUGE-1 F1: {scores['rouge-1']['f']:.4f}, ROUGE-2 F1: {scores['rouge-2']['f']:.4f}, ROUGE-L F1: {scores['rouge-l']['f']:.4f}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJ6iraEKnB5h",
        "outputId": "36b24e07-1ea3-49ee-aa97-7c0bea8b7e33"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Sentences and ROUGE Scores:\n",
            "Sentence 1: On 27 August 1907, a gas @-@ filled maze. Major streets were cleared or rejected on a misinterpretation of history and cultural events. Major government buildings are churches built before the year was a success, finishing as the Cardiff International Pool, Cardiff International White Water and Gordon was arrested on suspicion of murder at 8.00am the next film as a boulevard, a type of thing. The dedication ceremony was attended by 1 @,@ 076 hectare Roderick Haig @-@ Brown Provincial Park and fort today\n",
            "ROUGE-1 F1: 0.0041, ROUGE-2 F1: 0.0005, ROUGE-L F1: 0.0041\n",
            "\n",
            "Sentence 2: Hoover Dam, once known as a front line the northern bases was day after the earthquake @-@ ravaged city.\n",
            "ROUGE-1 F1: 0.0012, ROUGE-2 F1: 0.0002, ROUGE-L F1: 0.0012\n",
            "\n",
            "Sentence 3: The song is an example of a covenant offered by God to the south and Port Elizabeth. It is unusual for track and field as it moved southwestward. The very high encounter rate, and was moderately religious. He earned a bachelor's degree in English and French warships were in danger from storm surge.\n",
            "ROUGE-1 F1: 0.0032, ROUGE-2 F1: 0.0005, ROUGE-L F1: 0.0031\n",
            "\n",
            "Sentence 4: This movement is prompted by the Turks back over the stumps or struck them. The Commission chose the United Kingdom in the semifinals and advance into the sea coast while the 3000 m is held at York Racecourse, Oyebanjo was voted the Finals MVP, having led all scorers averaging 33 @.@ 5 %. On January 31, 1861\n",
            "ROUGE-1 F1: 0.0033, ROUGE-2 F1: 0.0004, ROUGE-L F1: 0.0033\n",
            "\n",
            "Sentence 5: In 1983, it held approximately 7 % of to the route runs due east through Europe to control both Hum and Dubrava counties, which incorporated much of the freeway saw increased traffic. Wilson Avenue experienced a large yacht in 1997, and has been certified double platinum. It achieved No. 1 Federer at the top tier of non @-@ FIFA nationality.\n",
            "ROUGE-1 F1: 0.0036, ROUGE-2 F1: 0.0003, ROUGE-L F1: 0.0035\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Zq9ZbQVhym24SFBG9pGqicaAtC0Zblg2",
      "authorship_tag": "ABX9TyO1khbRL2QGUfgByrI4QsQN",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}